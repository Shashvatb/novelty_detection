{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db883ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "from os.path import join\n",
    "from utils import load_data, gen_observations, load_featurizer\n",
    "from mem_net import run_mem_net, test_mem_network\n",
    "from data_processing.data_extract import get_data_path\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "logger.setLevel(logging.DEBUG)\n",
    "cache_pickle = \"{}.pkl\"\n",
    "cache_dir = \".cache-pythia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b407f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_name='trec'):\n",
    "    \"\"\"\n",
    "    controls the over-arching implmentation of the algorithms\n",
    "    \"\"\"\n",
    "    print('starting')\n",
    "    path = get_data_path(dataset_name)\n",
    "    directory = {\n",
    "        'full_data': [join(path, '2003_preprocessed.parquet'), join(path, '2004_preprocessed.parquet')]\n",
    "    }\n",
    "    algorithms = {}\n",
    "\n",
    "    # parsing\n",
    "    print(\"parsing json data...\", file=sys.stderr)\n",
    "\n",
    "    data = load_data(directory['full_data'])\n",
    "\n",
    "    # featurization\n",
    "    tokenizer, bert = load_featurizer()\n",
    "    print(\"generating training data...\", file=sys.stderr)\n",
    "    train_data, train_target, train_ids = gen_observations(data, tokenizer, bert)\n",
    "    print(\"generating testing data...\", file=sys.stderr)\n",
    "    test_data, test_target, test_ids = gen_observations(data, tokenizer, bert)\n",
    "\n",
    "    # modeling\n",
    "    print(\"running algorithms...\", file=sys.stderr)\n",
    "    mem_net_model, model_name = run_mem_net(train_data, test_data, **algorithms['mem_net'])\n",
    "    predicted_labels, perform_results = test_mem_network(mem_net_model, model_name,\n",
    "                                                         **algorithms['mem_net'])\n",
    "\n",
    "    # results\n",
    "    perform_results = {\n",
    "        \"id\": test_ids,\n",
    "        \"predicted_label\": predicted_labels.tolist(),\n",
    "        \"novelty\": test_target\n",
    "    }\n",
    "\n",
    "    return perform_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed31a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(\"Algorithm details and Results:\", file=sys.stderr)\n",
    "    print(main(), file=sys.stdout)\n",
    "    sys.exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
